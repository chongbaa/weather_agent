## --启航篇|极速破界AI新时代
### ---LLM基础认知和核心原理
#### ----LLM基础认知
##### -----初识LLM
###### ------ai演进和LLM兴起
###### ------[[LLM 和 AGI]]
##### -----主流LLM和应用产品
##### -----LLM赋能行业分析
###### ------重点行业预测
###### ------LLM赋能行业通用场景应用分析
###### ------LLM赋能分行业分析
-------LLM+金融
-------LLM+政务
-------LLM+医疗
-------LLM+法律、游戏、教育、电商
##### -----LLM的发展趋势和挑战
-------Prompt
-------RAG
-------微调
#### ----LLM核心原理
##### -----LLM和传统机器学习的区别
##### -----Transformer架构
###### ------为什么会用到Transformer
###### ------什么是Transformer
###### ------RNN的原理和局限性
###### ------Transformer架构分析
##### -----LLM运行基本机制
###### ------LLM如何理解和表示单词
-------LLM处理单元
-------单元的远近亲疏关系
-------LLM词义的载体和表现特征
###### ------LLM如何理解和预测输入的内容
-------注意力机制
-------自注意力机制
-------基于语义理解的内容生成
##### -----预训练、SFT、RLHF

### ---提示词工程特训
#### ----提示词工程基础原理进阶技巧
#### ----提示词工程实战应用集
-------小红书文案生成
-------基于提示词的学院辅导系统实现
-------企业运营成本分析核算
-------数据库多表联合查询SQL代码生成
#### ----提示词工程经验总结


## --攻坚篇|RAG开发实战工坊
### ---RAG高频场景
#### ----检索增强生成前沿
##### -----LLM缺陷分析
##### -----RAG的定义
##### -----RAG的三大范式
#### ----Naive RAG Pipeline
##### -----知识库构建
###### ------文档加载与摄取
###### ------文档分块策略
##### -----索引&向量化
###### ------embedding向量化
-------向量定义与向量化的意义
-------向量化实践
--------*向量模型的API调用*
--------*基于Ollama的向量模型本地部署*
###### ------向量间的相似度计算
-------余弦相似度Cosine
-------欧式距离L2
###### ------Index “Top-K”的语义检索
##### -----向量数据库及实战
###### ------主流向量数据库对比
###### ------如何选型向量数据库
#### ----应用实战：向量检索HR制度智能问答系统
#### ----应用实战：混合检索医疗实体命名实战
### ---基于LangChain V0.3的全新重构
#### ----什么是LangChain？
#### ----LangChain体系
##### -----LangChain体系概览
##### -----LangChain的核心组件
#### ----LangChain应用程序生命周期
##### -----LangChain之Model I/O
##### -----Model 模型
###### ------聊天模型
###### ------提示模板
-------创建提示模板
-------直接生成提示模板
-------提示模板和大模型结合
-------ChatPromptTemplate聊天提示词模板
##### -----输出解析器
##### -----链（chain）
##### -----跟踪和调试
##### -----发布应用程序
#### ----增强提示词模板和输出解析器
##### -----增强提示词模板
###### ------少量样本示例的模板
###### ------提示模板部分格式化
##### -----输出解析器
#### ----LangChain的链和LCEL
##### -----链的基本使用
##### -----LCEL的高级特性与组件
###### ------Runnable Lambda
###### ------Runnable Parallel
###### ------Runnable Passthrough
###### ------Runnable With Message History
###### ------应用实战：多用户聊天机器人实战
###### ------应用实战：LCEL内置链读取在线WEB网页实战
###### ------查看链的元数据的输入输出
#### ----LangChain和RAG
##### -----文档与文档加载
##### -----文档转换器
##### -----文本嵌入模型
##### -----向量数据库
##### -----加入大模型进行提问
##### -----检索器
##### -----应用实战：基于LangChain的在线网页的RAG实现
#### ----LangChain的工具调用
##### -----工具Tools
##### -----应用实战：使用工具查询数据库表
### ---基于LancChain的RAG优化实践
#### ----RAG商业化痛点分析
##### -----文档加载准确性和效率
##### -----文档切分的程度
##### -----错过排名靠前的文档
##### -----提取上下文与答案无关
##### -----格式错误
##### -----答案不完整
##### -----未提取到答案
##### -----答案太具体或太笼统
##### -----幻觉问题
#### ----Advanced RAG
##### -----Advanced RAG原理
###### ------概述
###### ------Pre-Retrieval预检索
-------优化检索
--------*摘要索引*
--------*父子索引*
--------*假设性问题索引*
--------*元数据索引*

-------查询优化
--------*Enrich 完善问题*
--------*Multi-Query 多路召回*
--------*Decomposition 问题分解*
--------*查询优化小结*
###### ------检索优化-混合检索
-------本质
-------适用场景
-------实现
###### ------Post-Retrieval后检索
-------重排序
--------*Reranker模型*
--------*LongContextRecorder*
-------RAG-Fusion
-------上下文压缩和过滤
##### -----Advanced RAG实战
### ---RAG应用评估
#### ----评估方法
##### -----人工评估
##### -----自动化评估
#### ----评估类型和指标
##### -----检索评估
###### ------上下文相关性
###### ------上下文精度
###### ------上下文召回率
##### -----响应评估
###### ------忠实度
###### ------答案相关性
##### -----评估指标总结
##### -----常用评估工具介绍
###### ------Ragas主要的四个评估指标

#### ----应用实践：实战医疗评估

#### ----应用实践：评估选择合适的知识块大小
#### ----应用实践：2023年全球智能汽车AI挑战赛
### ---RAG开源项目剖析
#### ----RAGFlow应用分析
#### ----FastGPT应用分析
#### ----Dify应用分析

## --跃迁篇|Agent智能体架构设计
### ---人工智能的未来：Agent
#### ----Agent生态认知革命
##### -----Agent核心定义与运作原理解析
##### -----Agent任务结构
##### -----Agent应用开发框架
##### -----Agent应用实战：First Agent
##### -----Agent应用实战：Agents+Tools+Memory
#### ----Agent智调：Function Calling
##### -----从API到Agent：Function Calling诞生的技术必然性
##### -----Function Calling机制解析：从自然语言到结构化执行的范式转换
##### -----Function Calling全链路解析：从Prompt到API响应的完整工作流
##### -----Function Calling应用实战：动态SQL生成与数据库查询
##### -----Function Calling应用实战：12306实时票务接口对接
#### ----Agent核心认知框架
##### -----Agent实时决策：React
##### -----Agent策略蓝图：Plan-and-Execute
##### -----Agent回路验证：Self-Ask
##### -----Agent偏差修正：Thinking and Reflection
##### -----应用实战：命理机器人工程实践
### ---多Agent实践与数字人应用
#### ----多Agent系统
##### -----多Agent系统概述
###### ------从Agent到MAS的演进
###### ------什么是多Agent系统（MAS）
###### ------应用领域

##### -----AutoGen
###### ------AgentGen介绍
###### ------AgentChat
###### ------AutoGen Studio：让Agent开发像搭积木一样简单
###### ------应用实战：短视频自动生成工具
###### ------应用实战：多Agent协同代码生成应用
##### -----CrewAI
###### ------CrewAI基础认知
###### ------安装部署
###### ------应用实战：Job Posting 职位公布
#### ----Agent数字人应用
##### -----应用实战：实时交互数字人
##### -----应用实战：模拟面试机器人
### ---LangGraph
#### ----通识篇
##### -----LangChain与LangGraph的区别
##### -----LangGraph概述
##### -----LangGraph基础术语
#### ----指南篇
##### -----LangGraph API 基础
##### -----对图执行的细粒度控制
##### -----持久化拓展
##### -----内存管理
##### -----人工介入
##### -----工具调用
##### -----子图
##### -----多Agent
#### ----实战篇
##### -----基于LangGraph的旅游规划Agent
### ---可视化Agent框架/Agent IDE介绍
#### ----coze
##### -----coze概述
###### ------coze是什么
###### ------coze能做什么
###### ------注册账号
##### -----功能与优势
###### ------插件
###### ------工作流
-------什么是工作流
-------工作流和对话流的区别
-------工作流在coze中的表现形式
-------使用工作流--文章总结
###### ------图像流
-------什么是图像流
-------使用图像流--正装形象生成器
###### ------知识库
-------什么是知识库
-------为什么需要知识库
-------上传知识库
-------使用知识库
###### ------数据库
-------什么是数据库
-------使用数据库--访客管理系统
##### -----应用实战：coze实践AI咨询助手
## --精进篇|模型微调与私有化部署
### ---大模型生态与本地部署
#### ----开源LLM vs 闭源LLM
##### -----闭源模型局限性
##### -----开源模型优势
#### ----私有化模型部署的必要性
##### -----数据安全与隐私保护
##### -----业务定制化需求
##### -----性能与稳定性
##### -----成本可控和长期价值
#### ----国内外开源模型生态和能力对比
#### ----医疗健康大模型分析
##### -----在线问诊
###### ------LLama-7B中文
###### ------Consult医疗大模型
##### -----医患对话与问答
###### ------GPT4o
###### ------扁鹊健康大模型

### ---微调：打造垂直领域专家模型
#### ----模型微调简介 为什么需要模型微调
#### ----数据收集
##### -----通用微调数据
##### -----领域微调数据
##### -----不同数据配比下的微调效果对比
##### -----通用优质微调数据集推荐
##### -----领域微调数据集收集方式
###### ------网络爬虫
###### ------大模型蒸馏数据
###### ------基于下游任务数据集构造
#### ----应用场景确定
#### ----确定备选模型
#### ----微调模型测试题收集
#### ----模型微调
##### -----PEFT主流技术介绍
###### ------Adapter Tuning原理解析
###### ------Prompt Tuning 原理解析
###### ------Perfix Tuning 原理解析
##### -----LoRA低秩适配微调
###### ------算法原理解析
###### ------性能效果分析
##### -----Freeze微调
###### ------参数冻结原理解析
###### ------性能优缺点分析
##### -----如何选择
###### ------全参微调 vs PETF微调
###### ------全参微调 vs PETF微调成本对比
##### -----微调工具
###### ------LLaMA Factory框架介绍
###### ------Swift框架介绍
#### ----LLM评估体系
##### -----开源模型评估方式
###### ------自动化评估
###### ------人工评估
###### ------大模型评估
##### -----大模型评估框架
##### -----评估内容和标准
##### -----评估框架解析
###### ------HELE
###### ------SuperClue
###### ------C-Eval
###### ------MedBench
#### ----微调实战：大造医疗领域模型微调实战
### ---量化：模型压缩与加速推理
#### ----模型显存占用和量化技术简介
#### ----大模型量化算法
#### ----模型量化对比实例
#### ----量化效果优化SmoothQuant
#### ----大模型量化推理框架

### ---多模态大模型架解读
#### ----什么是多模态模型
#### ----多模态应用场景
#### ----图像生成技术概述
#### ----非标记化构架流程解析
##### -----BLIP2深度解析
###### ------工作流程分析
###### ------训练过程分析
##### -----Qwen2-VL深度解析
###### ------工作流程分析
###### ------训练过程分析
#### ----标记化构架流程解析 Chameleon 深度解析
##### -----工作流程分析
##### -----训练过程分析
#### ----标准交叉注意力 Ramingo 深度解析
##### -----工作流程分析
##### -----训练过程分析
#### ----定制融合层 CogVLM 深度解析
##### -----工作流程分析
##### -----训练过程分析
#### ----不同多模态大模型构架对比与场景选择判断
#### ----领域多模态大模型训练
##### -----训练目的
##### -----训练方式
###### ------LLaVA-Med
###### ------Med-Flamingo
###### ------RadFM
##### -----不同训练方式对比分析与场景选择
#### ----实战演示：基于Qwen2-VL领域多模态大模型训练实例
##### -----模型训练技术选型
----- 模型训练方案选择
##### -----模型训练数据解读
##### -----模型训练方法探索
##### -----模型训练效果评估
##### -----模型训练前后效果对比
### ---DeepSeek-V3及DeepSeek-R1技术详解
#### ----多头潜在注意力（MLA）框架
#### ----混合专家（MoE）框架
#### ----多词源预测（MTP）框架
#### ----无辅助损失的负载均衡策略
#### ----R1-Zero训练模版和奖励设计
#### ----复现结果：强化学习复现R1-Zero强化学习训练过程中推理能力的涌现